{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:cyan\"> Parte 1: Registro de los archivos en la base de datos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\"> Generar una nueva base de datos con la siguiente nomenclatura: apellido_nombre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "database_name = 'sepulveda_rodrigo'\n",
    "\n",
    "# Datos conexión\n",
    "host='localhost'\n",
    "dbname='sepulveda_rodrigo'\n",
    "user='postgres'\n",
    "password='qwertyu8'\n",
    "\n",
    "# Crear la base de datos\n",
    "connection = psycopg2.connect(host=host, user=user, password=password)\n",
    "connection.autocommit = True\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(f\"CREATE DATABASE {database_name};\")\n",
    "\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\"> Importar en tablas los archivos train_cupid.csv y test_cupid.csv a un motor Postgres, implementando solo la librería psycopg2. Las tablas deben contener los nombres de las columnas y el total de los registros presente en cada archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conexión a la base de datos\n",
    "connection = psycopg2.connect(host=host, dbname=dbname, user=user, password=password)\n",
    "# Crear un cursor\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Nombre de las tablas\n",
    "tabla_train = 'train_cupid'\n",
    "tabla_test = 'test_cupid'\n",
    "\n",
    "# Importar archivo train_cupid.csv\n",
    "with open('train_cupid.csv', 'r') as file:\n",
    "    # Leer el archivo CSV\n",
    "    reader = csv.reader(file)\n",
    "    \n",
    "    # Obtener los nombres de las columnas\n",
    "    header = next(reader)\n",
    "    \n",
    "    # Crear la tabla en la base de datos\n",
    "    column_definitions = \", \".join(f'\"{column}\" FLOAT' for column in header)\n",
    "    cursor.execute(f'CREATE TABLE {tabla_train} ({column_definitions})')\n",
    "    \n",
    "    # Insertar los registros en la tabla\n",
    "    for row in reader:\n",
    "        cursor.execute(f\"INSERT INTO {tabla_train} VALUES ({', '.join(['%s'] * len(row))})\", row)\n",
    "\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar archivo test_cupid.csv\n",
    "with open('test_cupid.csv', 'r') as file:\n",
    "    # Leer el archivo CSV\n",
    "    reader = csv.reader(file)\n",
    "    \n",
    "    # Obtener los nombres de las columnas\n",
    "    header = next(reader)\n",
    "    \n",
    "    # Crear la tabla en la base de datos\n",
    "    column_definitions = \", \".join(f'\"{column}\" FLOAT' for column in header)\n",
    "    cursor.execute(f'CREATE TABLE {tabla_test} ({column_definitions})')\n",
    "    \n",
    "    # Insertar los registros en la tabla\n",
    "    for row in reader:\n",
    "        cursor.execute(f\"INSERT INTO {tabla_test} VALUES ({', '.join(['%s'] * len(row))})\", row)\n",
    "\n",
    "connection.commit()\n",
    "\n",
    "# Cerrar cursor y conexión\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:cyan\"> Parte 2: Entrenamiento de modelos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\"> Ingestar la tabla de training mediante psycopg2 para el posterior entrenamiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conexión a la base de datos\n",
    "connection = psycopg2.connect(host=host, dbname=dbname, user=user, password=password)\n",
    "# Crear un cursor\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>virgo</th>\n",
       "      <th>taurus</th>\n",
       "      <th>scorpio</th>\n",
       "      <th>pisces</th>\n",
       "      <th>libra</th>\n",
       "      <th>leo</th>\n",
       "      <th>gemini</th>\n",
       "      <th>aries</th>\n",
       "      <th>...</th>\n",
       "      <th>orientation_straight</th>\n",
       "      <th>sex_m</th>\n",
       "      <th>smokes_sometimes</th>\n",
       "      <th>smokes_trying to quit</th>\n",
       "      <th>smokes_when drinking</th>\n",
       "      <th>smokes_yes</th>\n",
       "      <th>body_type_overweight</th>\n",
       "      <th>body_type_regular</th>\n",
       "      <th>education_high_school</th>\n",
       "      <th>education_undergrad_university</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20076</th>\n",
       "      <td>33.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20077</th>\n",
       "      <td>22.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20078</th>\n",
       "      <td>28.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20079</th>\n",
       "      <td>31.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20080</th>\n",
       "      <td>27.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20081 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  height  virgo  taurus  scorpio  pisces  libra  leo  gemini  \\\n",
       "0      35.0    70.0    0.0     0.0      0.0     0.0    0.0  0.0     0.0   \n",
       "1      38.0    68.0    0.0     0.0      0.0     0.0    0.0  0.0     0.0   \n",
       "2      23.0    71.0    0.0     0.0      0.0     1.0    0.0  0.0     0.0   \n",
       "3      29.0    66.0    0.0     0.0      0.0     0.0    0.0  0.0     0.0   \n",
       "4      29.0    67.0    0.0     1.0      0.0     0.0    0.0  0.0     0.0   \n",
       "...     ...     ...    ...     ...      ...     ...    ...  ...     ...   \n",
       "20076  33.0    63.0    0.0     0.0      0.0     0.0    0.0  0.0     0.0   \n",
       "20077  22.0    65.0    0.0     0.0      0.0     0.0    0.0  0.0     0.0   \n",
       "20078  28.0    64.0    0.0     0.0      0.0     0.0    0.0  0.0     0.0   \n",
       "20079  31.0    62.0    0.0     0.0      0.0     0.0    0.0  0.0     0.0   \n",
       "20080  27.0    73.0    0.0     0.0      0.0     0.0    0.0  0.0     0.0   \n",
       "\n",
       "       aries  ...  orientation_straight  sex_m  smokes_sometimes  \\\n",
       "0        0.0  ...                   1.0    1.0               0.0   \n",
       "1        0.0  ...                   1.0    1.0               0.0   \n",
       "2        0.0  ...                   1.0    1.0               0.0   \n",
       "3        0.0  ...                   1.0    1.0               0.0   \n",
       "4        0.0  ...                   1.0    1.0               0.0   \n",
       "...      ...  ...                   ...    ...               ...   \n",
       "20076    0.0  ...                   1.0    0.0               0.0   \n",
       "20077    0.0  ...                   1.0    0.0               0.0   \n",
       "20078    0.0  ...                   1.0    0.0               0.0   \n",
       "20079    0.0  ...                   1.0    0.0               0.0   \n",
       "20080    0.0  ...                   1.0    1.0               0.0   \n",
       "\n",
       "       smokes_trying to quit  smokes_when drinking  smokes_yes  \\\n",
       "0                        0.0                   0.0         0.0   \n",
       "1                        0.0                   0.0         0.0   \n",
       "2                        0.0                   0.0         0.0   \n",
       "3                        0.0                   0.0         0.0   \n",
       "4                        0.0                   0.0         0.0   \n",
       "...                      ...                   ...         ...   \n",
       "20076                    0.0                   0.0         0.0   \n",
       "20077                    0.0                   0.0         0.0   \n",
       "20078                    0.0                   0.0         0.0   \n",
       "20079                    0.0                   0.0         0.0   \n",
       "20080                    1.0                   0.0         0.0   \n",
       "\n",
       "       body_type_overweight  body_type_regular  education_high_school  \\\n",
       "0                       0.0                1.0                    0.0   \n",
       "1                       0.0                1.0                    0.0   \n",
       "2                       0.0                1.0                    0.0   \n",
       "3                       0.0                0.0                    0.0   \n",
       "4                       0.0                1.0                    0.0   \n",
       "...                     ...                ...                    ...   \n",
       "20076                   0.0                0.0                    0.0   \n",
       "20077                   0.0                1.0                    0.0   \n",
       "20078                   0.0                0.0                    0.0   \n",
       "20079                   0.0                0.0                    0.0   \n",
       "20080                   0.0                0.0                    0.0   \n",
       "\n",
       "       education_undergrad_university  \n",
       "0                                 0.0  \n",
       "1                                 0.0  \n",
       "2                                 1.0  \n",
       "3                                 1.0  \n",
       "4                                 1.0  \n",
       "...                               ...  \n",
       "20076                             0.0  \n",
       "20077                             1.0  \n",
       "20078                             0.0  \n",
       "20079                             0.0  \n",
       "20080                             1.0  \n",
       "\n",
       "[20081 rows x 98 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# generación de consulta en el cursor\n",
    "cursor.execute(f'SELECT * FROM {tabla_train}')\n",
    "data_train = cursor.fetchall()\n",
    "\n",
    "# Cerrar cursor y conexión\n",
    "cursor.close()\n",
    "connection.close()\n",
    "\n",
    "# transformación de consulta en una lista antes de ingresarla como un pd.DataFrame\n",
    "df_train = pd.DataFrame(list(data_train))\n",
    "\n",
    "# renombro las columnas\n",
    "df_train.columns = header\n",
    "df_train\n",
    "\n",
    "# esto mismo se puede lograr con la siguiente línea de código pero está soportado de mejor manera con SQLAlchemy \n",
    "# pd.read_sql(sql='SELECT * FROM train_cupid;', con=connection)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\"> Entrenar los siguientes modelos (sin necesidad de ajustar por hiper parámetros):\n",
    "    - GradientBoostingClassifier\n",
    "    - AdaBoostClassifer\n",
    "    - RandomForestClassifier\n",
    "    - SVC\n",
    "    - DecisionTreeClassifier\n",
    "    - LogisticRegression\n",
    "    - BernoulliNB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_copy = df_train.copy()\n",
    "\n",
    "# vectores objetivo\n",
    "targets = ['available', 'seeing_someone', 'single']\n",
    "\n",
    "# modelos a implementar\n",
    "models = {\n",
    "        'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "        'AdaBoostClassifier': AdaBoostClassifier(),\n",
    "        'RandomForestClassifier': RandomForestClassifier(),\n",
    "        'SVC': SVC(),\n",
    "        'DecisionTreeClassifier': DecisionTreeClassifier(),\n",
    "        'LogisticRegression': LogisticRegression(max_iter=5000),\n",
    "        'BernoulliNB': BernoulliNB()\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Se ingresó el hiperparámetro max_iter=5000 en 'LogisticRegression' ya que al ajustar el modelo arrojaba error y una de las soluciones era implementar este hiperparámetro."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\"> Serializar el objeto y preservarlo por cada combinación de modelo entrenado y vector objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "serialized_models = {}\n",
    "\n",
    "# matriz atributos entrenamiento\n",
    "X_train = df_train_copy.drop(targets, axis=1)\n",
    "\n",
    "# Entrenar los modelos y serializarlos por cada combinación de modelo y vector objetivo\n",
    "for target in targets:\n",
    "\n",
    "    # vector objetivo entrenamiento\n",
    "    y_train = df_train_copy[target]\n",
    "\n",
    "    # Inicializar y entrenar los modelos\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Serializar el objeto del modelo entrenado\n",
    "        pickle.dump(model, open('Modelo_' + model_name + '_' + target + '.pkl', 'wb')) \n",
    "\n",
    "        # guardado de nombre de modelos en diccionario\n",
    "        serialized_models['Modelo_' + model_name + '_' + target + '.pkl'] = model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:cyan\"> Parte 3: Exportación de predicciones"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\"> Ingestar la tabla de testing mediante psycopg2 para la posterior predicción del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conexión a la base de datos\n",
    "connection = psycopg2.connect(host=host, dbname=dbname, user=user, password=password)\n",
    "# Crear un cursor\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>virgo</th>\n",
       "      <th>taurus</th>\n",
       "      <th>scorpio</th>\n",
       "      <th>pisces</th>\n",
       "      <th>libra</th>\n",
       "      <th>leo</th>\n",
       "      <th>gemini</th>\n",
       "      <th>aries</th>\n",
       "      <th>...</th>\n",
       "      <th>orientation_straight</th>\n",
       "      <th>sex_m</th>\n",
       "      <th>smokes_sometimes</th>\n",
       "      <th>smokes_trying to quit</th>\n",
       "      <th>smokes_when drinking</th>\n",
       "      <th>smokes_yes</th>\n",
       "      <th>body_type_overweight</th>\n",
       "      <th>body_type_regular</th>\n",
       "      <th>education_high_school</th>\n",
       "      <th>education_undergrad_university</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19938</th>\n",
       "      <td>48.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19939</th>\n",
       "      <td>52.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19940</th>\n",
       "      <td>59.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19941</th>\n",
       "      <td>24.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19942</th>\n",
       "      <td>39.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19943 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  height  virgo  taurus  scorpio  pisces  libra  leo  gemini  \\\n",
       "0      22.0    75.0    0.0     0.0      0.0     0.0    0.0  0.0     1.0   \n",
       "1      32.0    65.0    1.0     0.0      0.0     0.0    0.0  0.0     0.0   \n",
       "2      24.0    67.0    0.0     0.0      0.0     0.0    0.0  0.0     0.0   \n",
       "3      29.0    62.0    0.0     1.0      0.0     0.0    0.0  0.0     0.0   \n",
       "4      39.0    65.0    0.0     0.0      0.0     0.0    0.0  0.0     0.0   \n",
       "...     ...     ...    ...     ...      ...     ...    ...  ...     ...   \n",
       "19938  48.0    73.0    0.0     0.0      0.0     0.0    0.0  0.0     0.0   \n",
       "19939  52.0    70.0    0.0     0.0      0.0     0.0    0.0  0.0     0.0   \n",
       "19940  59.0    62.0    0.0     0.0      0.0     0.0    0.0  0.0     0.0   \n",
       "19941  24.0    72.0    0.0     0.0      0.0     0.0    0.0  0.0     0.0   \n",
       "19942  39.0    68.0    0.0     0.0      0.0     0.0    0.0  0.0     0.0   \n",
       "\n",
       "       aries  ...  orientation_straight  sex_m  smokes_sometimes  \\\n",
       "0        0.0  ...                   1.0    1.0               1.0   \n",
       "1        0.0  ...                   1.0    0.0               0.0   \n",
       "2        0.0  ...                   1.0    0.0               0.0   \n",
       "3        0.0  ...                   1.0    0.0               0.0   \n",
       "4        0.0  ...                   1.0    0.0               0.0   \n",
       "...      ...  ...                   ...    ...               ...   \n",
       "19938    0.0  ...                   1.0    1.0               0.0   \n",
       "19939    0.0  ...                   1.0    1.0               0.0   \n",
       "19940    0.0  ...                   1.0    0.0               0.0   \n",
       "19941    0.0  ...                   1.0    1.0               0.0   \n",
       "19942    0.0  ...                   0.0    1.0               1.0   \n",
       "\n",
       "       smokes_trying to quit  smokes_when drinking  smokes_yes  \\\n",
       "0                        0.0                   0.0         0.0   \n",
       "1                        0.0                   0.0         0.0   \n",
       "2                        0.0                   1.0         0.0   \n",
       "3                        0.0                   0.0         0.0   \n",
       "4                        0.0                   0.0         0.0   \n",
       "...                      ...                   ...         ...   \n",
       "19938                    0.0                   0.0         0.0   \n",
       "19939                    0.0                   0.0         0.0   \n",
       "19940                    0.0                   0.0         0.0   \n",
       "19941                    0.0                   0.0         0.0   \n",
       "19942                    0.0                   0.0         0.0   \n",
       "\n",
       "       body_type_overweight  body_type_regular  education_high_school  \\\n",
       "0                       0.0                0.0                    0.0   \n",
       "1                       0.0                0.0                    0.0   \n",
       "2                       0.0                0.0                    0.0   \n",
       "3                       0.0                1.0                    0.0   \n",
       "4                       0.0                0.0                    0.0   \n",
       "...                     ...                ...                    ...   \n",
       "19938                   0.0                1.0                    0.0   \n",
       "19939                   0.0                0.0                    0.0   \n",
       "19940                   0.0                0.0                    0.0   \n",
       "19941                   0.0                0.0                    0.0   \n",
       "19942                   0.0                1.0                    0.0   \n",
       "\n",
       "       education_undergrad_university  \n",
       "0                                 1.0  \n",
       "1                                 1.0  \n",
       "2                                 1.0  \n",
       "3                                 1.0  \n",
       "4                                 1.0  \n",
       "...                               ...  \n",
       "19938                             0.0  \n",
       "19939                             1.0  \n",
       "19940                             1.0  \n",
       "19941                             1.0  \n",
       "19942                             0.0  \n",
       "\n",
       "[19943 rows x 98 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generación de consulta en el cursor\n",
    "cursor.execute(f'SELECT * FROM {tabla_test}')\n",
    "data_test = cursor.fetchall()\n",
    "\n",
    "# Cerrar cursor y conexión\n",
    "cursor.close()\n",
    "connection.close()\n",
    "\n",
    "# transformación de consulta en una lista antes de ingresarla como un pd.DataFrame\n",
    "df_test = pd.DataFrame(list(data_test))\n",
    "\n",
    "# renombro las columnas\n",
    "df_test.columns = header\n",
    "df_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\"> En base a los objetos serializados, predecir y evaluar cuatro queries específicas:\n",
    "    - Query 1: 'atheism', 'asian', 'employed', 'pro_dogs', 'chinese'.\n",
    "    - Query 2: 'income_over_75', 'french', 'german','orientation_straight', 'new york'.\n",
    "    - Query 3: 'education_undergrad_university', 'body_type_regular', 'pro_dogs', 'employed'.\n",
    "    - Query 4: 'taurus', 'indian', 'washington', 'income_between_50_75', 'hinduism'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_copy = df_test.copy()\n",
    "\n",
    "# matriz atributos datos validación\n",
    "X_test = df_test_copy.drop(targets, axis=1)\n",
    "\n",
    "# y_test de cada vector objetivo\n",
    "y_test_available = df_test_copy['available']\n",
    "y_test_seeing_someone =df_test_copy['seeing_someone']\n",
    "y_test_single =df_test_copy['single']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# función para calcular las predicciones\n",
    "def predictions(model, X_test):\n",
    "    yhat_temp = model.predict(X_test)\n",
    "    return yhat_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtención de predicciones de los modelos serializados\n",
    "y_hat_dict = {}\n",
    "\n",
    "for key in serialized_models.keys():\n",
    "    modelo_pickle_ajustado = pickle.load(open(key,\"rb\"))\n",
    "    y_hat_test = predictions(modelo_pickle_ajustado, X_test)\n",
    "    y_hat_dict[key.replace('Modelo_', '').replace('.pkl', '_predictions')] = y_hat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe que contiene las predicciones para los 21 modelos obtenidos\n",
    "df_yhat_test = pd.DataFrame(y_hat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenación df_yhat_test con X_test\n",
    "df_concat = pd.concat([X_test, df_yhat_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# función que imprime los classification report para cada vector objetivo\n",
    "def classif_report(target):\n",
    "    if target == 'available':\n",
    "        print('*'*13,'Vector objetivo available','*'*13, '\\n')\n",
    "        for prediction in df_yhat_test.iloc[:,:7]:\n",
    "            print(f'Métricas para {prediction.replace(\"_predictions\", \"\")}:')\n",
    "            print(classification_report(y_test_available, df_yhat_test[prediction]), '\\n', '-'*60, '\\n')\n",
    "\n",
    "    elif target == 'seeing_someone':\n",
    "        print('*'*13,'Vector objetivo seeing_someone','*'*13, '\\n')\n",
    "        for prediction in df_yhat_test.iloc[:, 7:14]:\n",
    "            print(f'Métricas para {prediction.replace(\"_predictions\", \"\")}:')\n",
    "            print(classification_report(y_test_seeing_someone, df_yhat_test[prediction]), '\\n', '-'*60, '\\n')\n",
    "\n",
    "    elif target == 'single':\n",
    "        print('*'*14,'Vector objetivo single','*'*14, '\\n')\n",
    "        for prediction in df_yhat_test.iloc[:, 14:]:\n",
    "            print(f'Métricas para {prediction.replace(\"_predictions\", \"\")}:')\n",
    "            print(classification_report(y_test_single, df_yhat_test[prediction]), '\\n', '-'*60, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* Vector objetivo available ************* \n",
      "\n",
      "Métricas para GradientBoostingClassifier_available:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98     19163\n",
      "         1.0       0.00      0.00      0.00       780\n",
      "\n",
      "    accuracy                           0.96     19943\n",
      "   macro avg       0.48      0.50      0.49     19943\n",
      "weighted avg       0.92      0.96      0.94     19943\n",
      " \n",
      " ------------------------------------------------------------ \n",
      "\n",
      "Métricas para AdaBoostClassifier_available:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98     19163\n",
      "         1.0       0.00      0.00      0.00       780\n",
      "\n",
      "    accuracy                           0.96     19943\n",
      "   macro avg       0.48      0.50      0.49     19943\n",
      "weighted avg       0.92      0.96      0.94     19943\n",
      " \n",
      " ------------------------------------------------------------ \n",
      "\n",
      "Métricas para RandomForestClassifier_available:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98     19163\n",
      "         1.0       0.00      0.00      0.00       780\n",
      "\n",
      "    accuracy                           0.96     19943\n",
      "   macro avg       0.48      0.50      0.49     19943\n",
      "weighted avg       0.92      0.96      0.94     19943\n",
      " \n",
      " ------------------------------------------------------------ \n",
      "\n",
      "Métricas para SVC_available:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98     19163\n",
      "         1.0       0.00      0.00      0.00       780\n",
      "\n",
      "    accuracy                           0.96     19943\n",
      "   macro avg       0.48      0.50      0.49     19943\n",
      "weighted avg       0.92      0.96      0.94     19943\n",
      " \n",
      " ------------------------------------------------------------ \n",
      "\n",
      "Métricas para DecisionTreeClassifier_available:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.95      0.96     19163\n",
      "         1.0       0.07      0.09      0.08       780\n",
      "\n",
      "    accuracy                           0.92     19943\n",
      "   macro avg       0.51      0.52      0.52     19943\n",
      "weighted avg       0.93      0.92      0.92     19943\n",
      " \n",
      " ------------------------------------------------------------ \n",
      "\n",
      "Métricas para LogisticRegression_available:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98     19163\n",
      "         1.0       0.00      0.00      0.00       780\n",
      "\n",
      "    accuracy                           0.96     19943\n",
      "   macro avg       0.48      0.50      0.49     19943\n",
      "weighted avg       0.92      0.96      0.94     19943\n",
      " \n",
      " ------------------------------------------------------------ \n",
      "\n",
      "Métricas para BernoulliNB_available:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98     19163\n",
      "         1.0       0.09      0.00      0.00       780\n",
      "\n",
      "    accuracy                           0.96     19943\n",
      "   macro avg       0.52      0.50      0.49     19943\n",
      "weighted avg       0.93      0.96      0.94     19943\n",
      " \n",
      " ------------------------------------------------------------ \n",
      "\n",
      "************* Vector objetivo seeing_someone ************* \n",
      "\n",
      "Métricas para GradientBoostingClassifier_seeing_someone:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98     19163\n",
      "         1.0       0.00      0.00      0.00       780\n",
      "\n",
      "    accuracy                           0.96     19943\n",
      "   macro avg       0.48      0.50      0.49     19943\n",
      "weighted avg       0.92      0.96      0.94     19943\n",
      " \n",
      " ------------------------------------------------------------ \n",
      "\n",
      "Métricas para AdaBoostClassifier_seeing_someone:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98     19163\n",
      "         1.0       0.00      0.00      0.00       780\n",
      "\n",
      "    accuracy                           0.96     19943\n",
      "   macro avg       0.48      0.50      0.49     19943\n",
      "weighted avg       0.92      0.96      0.94     19943\n",
      " \n",
      " ------------------------------------------------------------ \n",
      "\n",
      "Métricas para RandomForestClassifier_seeing_someone:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98     19163\n",
      "         1.0       0.00      0.00      0.00       780\n",
      "\n",
      "    accuracy                           0.96     19943\n",
      "   macro avg       0.48      0.50      0.49     19943\n",
      "weighted avg       0.92      0.96      0.94     19943\n",
      " \n",
      " ------------------------------------------------------------ \n",
      "\n",
      "Métricas para SVC_seeing_someone:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98     19163\n",
      "         1.0       0.00      0.00      0.00       780\n",
      "\n",
      "    accuracy                           0.96     19943\n",
      "   macro avg       0.48      0.50      0.49     19943\n",
      "weighted avg       0.92      0.96      0.94     19943\n",
      " \n",
      " ------------------------------------------------------------ \n",
      "\n",
      "Métricas para DecisionTreeClassifier_seeing_someone:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.95      0.95     19163\n",
      "         1.0       0.06      0.09      0.07       780\n",
      "\n",
      "    accuracy                           0.91     19943\n",
      "   macro avg       0.51      0.52      0.51     19943\n",
      "weighted avg       0.93      0.91      0.92     19943\n",
      " \n",
      " ------------------------------------------------------------ \n",
      "\n",
      "Métricas para LogisticRegression_seeing_someone:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98     19163\n",
      "         1.0       0.00      0.00      0.00       780\n",
      "\n",
      "    accuracy                           0.96     19943\n",
      "   macro avg       0.48      0.50      0.49     19943\n",
      "weighted avg       0.92      0.96      0.94     19943\n",
      " \n",
      " ------------------------------------------------------------ \n",
      "\n",
      "Métricas para BernoulliNB_seeing_someone:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98     19163\n",
      "         1.0       0.09      0.00      0.00       780\n",
      "\n",
      "    accuracy                           0.96     19943\n",
      "   macro avg       0.52      0.50      0.49     19943\n",
      "weighted avg       0.93      0.96      0.94     19943\n",
      " \n",
      " ------------------------------------------------------------ \n",
      "\n",
      "************** Vector objetivo single ************** \n",
      "\n",
      "Métricas para GradientBoostingClassifier_single:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.03      0.05      1616\n",
      "         1.0       0.92      1.00      0.96     18327\n",
      "\n",
      "    accuracy                           0.92     19943\n",
      "   macro avg       0.72      0.51      0.50     19943\n",
      "weighted avg       0.89      0.92      0.88     19943\n",
      " \n",
      " ------------------------------------------------------------ \n",
      "\n",
      "Métricas para AdaBoostClassifier_single:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.35      0.01      0.03      1616\n",
      "         1.0       0.92      1.00      0.96     18327\n",
      "\n",
      "    accuracy                           0.92     19943\n",
      "   macro avg       0.64      0.51      0.49     19943\n",
      "weighted avg       0.87      0.92      0.88     19943\n",
      " \n",
      " ------------------------------------------------------------ \n",
      "\n",
      "Métricas para RandomForestClassifier_single:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.29      0.02      0.03      1616\n",
      "         1.0       0.92      1.00      0.96     18327\n",
      "\n",
      "    accuracy                           0.92     19943\n",
      "   macro avg       0.61      0.51      0.49     19943\n",
      "weighted avg       0.87      0.92      0.88     19943\n",
      " \n",
      " ------------------------------------------------------------ \n",
      "\n",
      "Métricas para SVC_single:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      1616\n",
      "         1.0       0.92      1.00      0.96     18327\n",
      "\n",
      "    accuracy                           0.92     19943\n",
      "   macro avg       0.46      0.50      0.48     19943\n",
      "weighted avg       0.84      0.92      0.88     19943\n",
      " \n",
      " ------------------------------------------------------------ \n",
      "\n",
      "Métricas para DecisionTreeClassifier_single:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.15      0.18      0.16      1616\n",
      "         1.0       0.93      0.91      0.92     18327\n",
      "\n",
      "    accuracy                           0.85     19943\n",
      "   macro avg       0.54      0.54      0.54     19943\n",
      "weighted avg       0.86      0.85      0.86     19943\n",
      " \n",
      " ------------------------------------------------------------ \n",
      "\n",
      "Métricas para LogisticRegression_single:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.41      0.02      0.04      1616\n",
      "         1.0       0.92      1.00      0.96     18327\n",
      "\n",
      "    accuracy                           0.92     19943\n",
      "   macro avg       0.67      0.51      0.50     19943\n",
      "weighted avg       0.88      0.92      0.88     19943\n",
      " \n",
      " ------------------------------------------------------------ \n",
      "\n",
      "Métricas para BernoulliNB_single:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.29      0.05      0.08      1616\n",
      "         1.0       0.92      0.99      0.95     18327\n",
      "\n",
      "    accuracy                           0.91     19943\n",
      "   macro avg       0.61      0.52      0.52     19943\n",
      "weighted avg       0.87      0.91      0.88     19943\n",
      " \n",
      " ------------------------------------------------------------ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report para los vectores objetivos\n",
    "classif_report('available')\n",
    "classif_report('seeing_someone')\n",
    "classif_report('single')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    ['atheism', 'asian', 'employed', 'pro_dogs', 'chinese'],\n",
    "    ['income_over_75', 'french', 'german', 'orientation_straight', 'new york'],\n",
    "    ['education_undergrad_university', 'body_type_regular', 'pro_dogs', 'employed'],\n",
    "    ['taurus', 'indian', 'washington', 'income_between_50_75', 'hinduism']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# función que retorna los resultados para cada query\n",
    "def result_query(query, model_target_yhat):\n",
    "    result_query = df_concat.groupby(query)[model_target_yhat].mean()\n",
    "    return result_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se guardan en una lista los resultados por query\n",
    "resultados = []\n",
    "for query_i in queries:\n",
    "    for y_hat in df_yhat_test.columns:\n",
    "        resultados.append(result_query(query=query_i, model_target_yhat=y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista para los nombres de las tablas que crearé en sql\n",
    "nombres_de_tablas=[]\n",
    "\n",
    "queries_name = ['query_1', 'query_2', 'query_3', 'query_4']\n",
    "for query in queries_name:\n",
    "    for i in range(0, 21):\n",
    "        nombres_de_tablas.append(resultados[i].name+'_'+query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# conexion a postgres usando sqlalchemy\n",
    "engine = create_engine('postgresql://' + user + ':' + password + '@' + host + '/' + dbname)\n",
    "\n",
    "def tabla_a_sql(indice, nombre_de_la_tabla):\n",
    "    # convierto tabla a dataframe\n",
    "    temp_df_resultado_i = resultados[indice].to_frame()\n",
    "\n",
    "    # ahora convierto de dataframe a tabla en sql\n",
    "    return temp_df_resultado_i.to_sql(nombre_de_la_tabla , con=engine, if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de tablas en sql\n",
    "for index, value in enumerate(nombres_de_tablas):\n",
    "    tabla_a_sql(index, value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
